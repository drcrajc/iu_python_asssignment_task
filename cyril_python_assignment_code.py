# -*- coding: utf-8 -*-
"""cyril_python_assignment_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FCvNP5v6yipw9KsTkE0P91_aZ9u4b5Bh
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
from keras.models import Sequential
from keras.layers import Dense
import matplotlib.pyplot as plt

# Load datasets
ideal_df = pd.read_csv("/content/drive/MyDrive/iubh_python_assign/dataset/ideal.csv")
test_df = pd.read_csv("/content/drive/MyDrive/iubh_python_assign/dataset/test.csv")
train_df = pd.read_csv("/content/drive/MyDrive/iubh_python_assign/dataset/train.csv")
print("Datasets loaded successfully")

# Prepare training and test data
X_train = train_df["x"].values.reshape(-1, 1)
y_train = train_df.drop(columns=["x"]).values.ravel()
X_test = test_df["x"].values.reshape(-1, 1)
print("Training and test data prepared")

# Define a function to fit models and calculate SSD
def fit_and_evaluate_model(model, model_name):
    models = []
    ssds = []

    for i in range(1, 51):
        y_ideal = ideal_df[f"y{i}"].values.ravel()
        model.fit(X_train, y_ideal)
        y_pred = model.predict(X_train)
        ssd = np.sum((y_pred - y_ideal)**2)  # Use y_ideal instead of y_train for SSD calculation
        models.append(model)
        ssds.append(ssd)
        print(f"{model_name} Model {i} fitted with SSD: {ssd}")

    return models, ssds

# Define a function to fit neural networks and calculate SSD
def fit_and_evaluate_nn():
    models = []
    ssds = []

    for i in range(1, 51):
        y_ideal = ideal_df[f"y{i}"].values.ravel()
        model = Sequential()
        model.add(Dense(64, input_dim=1, activation='relu'))
        model.add(Dense(32, activation='relu'))
        model.add(Dense(1))
        model.compile(optimizer='adam', loss='mean_squared_error')
        model.fit(X_train, y_ideal, epochs=100, verbose=0)
        y_pred = model.predict(X_train).flatten()
        ssd = np.sum((y_pred - y_ideal)**2)  # Use y_ideal instead of y_train for SSD calculation
        models.append(model)
        ssds.append(ssd)
        print(f"Neural Network Model {i} fitted with SSD: {ssd}")

    return models, ssds

# Fit and evaluate models
#Linear Regression
linear_models, linear_ssds = fit_and_evaluate_model(LinearRegression(), "Linear Regression")

#Random Forest Regression
rf_models, rf_ssds = fit_and_evaluate_model(RandomForestRegressor(n_estimators=100, random_state=0), "Random Forest")

#Support Vector Regression
svr_models, svr_ssds = fit_and_evaluate_model(SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1), "SVR")

#Gradient Boost Regression
gbr_models, gbr_ssds = fit_and_evaluate_model(GradientBoostingRegressor(n_estimators=100, random_state=0), "Gradient Boosting")

#k-Nearest Neighbours
knn_models, knn_ssds = fit_and_evaluate_model(KNeighborsRegressor(n_neighbors=5), "KNN")

#Neural Networks
nn_models, nn_ssds = fit_and_evaluate_nn()

# Prepare data for the Excel file
data = {
    "Ideal Function": [f"y{i}" for i in range(1, 51)],
    "SSD of LR": linear_ssds,
    "SSD of RF": rf_ssds,
    "SSD of SVR": svr_ssds,
    "SSD of GBR": gbr_ssds,
    "SSD of kNN": knn_ssds,
    "SSD of NN": nn_ssds,
}

# Create a DataFrame
ssds_df = pd.DataFrame(data)

# Save the DataFrame to an Excel file
ssds_df.to_excel("ssds_values.xlsx", index=False)

print("SSD values saved to 'ssds_values.xlsx'")

# Print the SSD values
print(ssds_df)

# Combine all SSDs and models
all_ssds = linear_ssds + rf_ssds + svr_ssds + gbr_ssds + knn_ssds + nn_ssds
all_models = linear_models + rf_models + svr_models + gbr_models + knn_models + nn_models

# Choose the four best models based on SSD
chosen_indices = np.argsort(all_ssds)[:4]
chosen_models = [all_models[i] for i in chosen_indices]
print(f"Chosen model indices: {chosen_indices}")

# Predict on test data and evaluate
test_predictions = np.zeros((len(X_test), 4))
mse_values = []
for i, model in enumerate(chosen_models):
    test_predictions[:, i] = model.predict(X_test).flatten()
    mse = mean_squared_error(test_df["y"], test_predictions[:, i])
    mse_values.append(mse)
    print(f"Predictions from model {chosen_indices[i] + 1} completed with MSE: {mse}")

# Visualize the results
plt.figure(figsize=(10, 6))
plt.scatter(X_test, test_df["y"], label="Test Data")
for i in range(4):
    plt.plot(X_test, test_predictions[:, i], label=f"Ideal Function {chosen_indices[i] + 1}")
plt.xlabel("x")
plt.ylabel("y")
plt.title("Test Data and Predictions")
plt.legend()
plt.grid(True)
plt.savefig("test_predictions.png")
plt.show()
print("Visualization completed and saved as 'test_predictions.png'")